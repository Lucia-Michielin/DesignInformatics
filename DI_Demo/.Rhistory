library(tidyverse)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
library(tidytext)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
library(janeaustenr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
get_sentiments("bing")
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>%
group_by(book, chapter) %>%
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>%
group_by(book, chapter, index) %>%
count(sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>%
group_by(book, chapter) %>%
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>%
group_by(book, chapter, index) %>%
count(sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative,index= as.factor(index))%>%
filter(!chapter=="0")
## create a directory to which the images will be written
dir_out <- file.path("Austen")
## create a directory to which the images will be written
dir_out <- file.path("output/Austen")
dir.create(dir_out, recursive = TRUE)
## create a directory to which the images will be written
dir_out <- file.path("outputs/Austen")
dir.create(dir_out, recursive = TRUE)
books <-
jane_austen_sentiment%>%
pull(book) %>%
unique(.) %>%
sort(.)
## look at what
books <- unique(jane_austen_sentiment$book)
## look at what
books <- unique(jane_austen_sentiment$book)
books
## find the month with the most houses sold to set y axis limit
most_chapter <- max(jane_austen_sentiment$chapter, na.rm = TRUE)
for (y in books) {
p <-
jane_austen_sentiment %>%
filter(book == y) %>%
ggplot(aes(chapter,index, fill= sentiment)) +
geom_tile() +
scale_x_continuous(breaks=seq(1,most_chapter,1), expand = c(0,0))+
scale_fill_gradient(low="blue", high="red", limits = c(-20, 40))+
theme_bw()+
guides(fill="none")+
ggtitle(y)+
coord_fixed(ratio = 1, ylim = c(10,1), xlim = c(0.5,most_chapter+0.5))+
theme(
axis.title.y = element_blank(),
axis.text.y= element_blank(),
axis.ticks.y = element_blank()
)
fp <- file.path(dir_out, paste0(y, ".png"))
ggsave(plot = p,
filename = fp,
device = "png",
width=3500, height = 1000, units = "px")
}
library("png")
pp <- readPNG("output/Austen/Emma.png")
library(imager)
install.packages("imager")
library(imager)
im<-load.image("output/Austen/Emma.png")
Image <- image_read('output/Austen/Emma.png')
library(magik)
library(magick)
Image <- image_read('output/Austen/Emma.png')
Image <- image_read('outputs/Austen/Emma.png')
Image
## list file names and read in
imgs <- list.files(dir_out, full.names = TRUE)
img_list <- lapply(imgs, image_read)
## join the images together
img_joined <- image_join(img_list)
## animate at 2 frames per second
img_animated <- image_animate(img_joined, fps = 1)
## view animated image
img_animated
## save to disk
image_write(image = img_animated,
path = "outputs/austen.gif")
View(tidy_books)
View(tidy_books)
View(tidy_books)
knitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE)
library(tidytext)
library(tidyverse)
library(janeaustenr)
library(magick)
AustenTable <- austen_books() %>% #create a new file named AustenTable that will extract info from austen_books
group_by(book) %>% # group by every single book then
mutate( # manipulate the data to create
linenumber = row_number(), # a line number column that would count in which row the word was
chapter = cumsum(str_detect(text, # the chapter number. We can do so by using regex and find lines starting with chapter followed by a space and a letter
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>% #  This line removes the grouping, so subsequent operations will be applied to the entire dataset rather than grouped subsets.
unnest_tokens(word, text) # This tokenises the text column, splitting it into individual words and creating a new row for each word
AustenTable <- austen_books() %>% #create a new file named AustenTable that will extract info from austen_books
group_by(book) %>% # group by every single book then
mutate( # manipulate the data to create
linenumber = row_number(), # a line number column that would count in which row the word was
chapter = cumsum(str_detect(text, # the chapter number. We can do so by using regex and find lines starting with chapter followed by a space and a letter
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>% #  This line removes the grouping, so subsequent operations will be applied to the entire dataset rather than grouped subsets.
unnest_tokens(word, text) # This tokenises the text column, splitting it into individual words and creating a new row for each word
head(AustenTable)
jane_austen_sentiment <- AustenTable %>% # Load Jane Austen's books dataset and start a chain of operations to create a Jane_austen_sentiment dataset
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>% # Join the dataset with the Bing lexicon sentiment dictionary
group_by(book, chapter) %>%   # Group the dataset by book and chapter
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>% # Create an index to split the chapters into 10 segments no matter how long the chapter it is
group_by(book, chapter, index) %>% # Regroup the dataset by book, chapter, and index
count(sentiment) %>%  # Count the occurrences of each sentiment within each segment
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% # Reshape the data from long to wide format
mutate(sentiment = positive - negative,index= as.factor(index))%>%  # Calculate sentiment score (positive - negative) for each segment
filter(!chapter=="0") # Filter out chapters with the value "0" (if any)
dir_out <- file.path("outputs/Austen") # Define the directory path where the outputs will be saved
dir.create(dir_out, recursive = TRUE) # Create the directory if it doesn't already exist
books <- unique(jane_austen_sentiment$book)
books
library(tidytext) # to work with unstructured data
library(tidyverse) # to do data wrangling
library(janeaustenr) # to fetch the dataset
library(magick) # to display images
AustenTable <- austen_books() %>% #create a new file named AustenTable that will extract info from austen_books
group_by(book) %>% # group by every single book then
mutate( # manipulate the data to create
linenumber = row_number(), # a line number column that would count in which row the word was
chapter = cumsum(str_detect(text, # the chapter number. We can do so by using regex and find lines starting with chapter followed by a space and a letter
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>% #  This line removes the grouping, so subsequent operations will be applied to the entire dataset rather than grouped subsets.
unnest_tokens(word, text) # This tokenises the text column, splitting it into individual words and creating a new row for each word
head(AustenTable)
```{r Austen Sentiment}
jane_austen_sentiment <- AustenTable %>% # Load Jane Austen's books dataset and start a chain of operations to create a Jane_austen_sentiment dataset
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>% # Join the dataset with the Bing lexicon sentiment dictionary
group_by(book, chapter) %>%   # Group the dataset by book and chapter
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>% # Create an index to split the chapters into 10 segments no matter how long the chapter it is
group_by(book, chapter, index) %>% # Regroup the dataset by book, chapter, and index
count(sentiment) %>%  # Count the occurrences of each sentiment within each segment
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% # Reshape the data from long to wide format
mutate(sentiment = positive - negative,index= as.factor(index))%>%  # Calculate sentiment score (positive - negative) for each segment
filter(!chapter=="0") # Filter out chapters with the value "0" (if any)
jane_austen_sentiment <- AustenTable %>% # Load Jane Austen's books dataset and start a chain of operations to create a Jane_austen_sentiment dataset
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>% # Join the dataset with the Bing lexicon sentiment dictionary
group_by(book, chapter) %>%   # Group the dataset by book and chapter
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>% # Create an index to split the chapters into 10 segments no matter how long the chapter it is
group_by(book, chapter, index) %>% # Regroup the dataset by book, chapter, and index
count(sentiment) %>%  # Count the occurrences of each sentiment within each segment
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% # Reshape the data from long to wide format
mutate(sentiment = positive - negative,index= as.factor(index))%>%  # Calculate sentiment score (positive - negative) for each segment
filter(!chapter=="0") # Filter out chapters with the value "0" (if any)
head(jane_austen_sentiment)
dir_out <- file.path("outputs/Austen") # Define the directory path where the outputs will be saved
dir.create(dir_out, recursive = TRUE) # Create the directory if it doesn't already exist
library(tidytext) # to work with unstructured data
library(tidyverse) # to do data wrangling
library(janeaustenr) # to fetch the dataset
library(magick) # to display images
# these are the libraries we need if you do not have them already and you get an error remove the # from the install.packages()lines
AustenTable <- austen_books() %>% #create a new file named AustenTable that will extract info from austen_books
group_by(book) %>% # group by every single book then
mutate( # manipulate the data to create
linenumber = row_number(), # a line number column that would count in which row the word was
chapter = cumsum(str_detect(text, # the chapter number. We can do so by using regex and find lines starting with chapter followed by a space and a letter
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>% #  This line removes the grouping, so subsequent operations will be applied to the entire dataset rather than grouped subsets.
unnest_tokens(word, text) # This tokenises the text column, splitting it into individual words and creating a new row for each word
head(AustenTable)
```{r Austen Sentiment}
jane_austen_sentiment <- AustenTable %>% # Load Jane Austen's books dataset and start a chain of operations to create a Jane_austen_sentiment dataset
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>% # Join the dataset with the Bing lexicon sentiment dictionary
group_by(book, chapter) %>%   # Group the dataset by book and chapter
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>% # Create an index to split the chapters into 10 segments no matter how long the chapter it is
group_by(book, chapter, index) %>% # Regroup the dataset by book, chapter, and index
count(sentiment)
View(jane_austen_sentiment)
View(jane_austen_sentiment)
get_sentiments("bing")
jane_austen_sentiment <- AustenTable %>% # Load Jane Austen's books dataset and start a chain of operations to create a Jane_austen_sentiment dataset
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>% # Join the dataset with the Bing lexicon sentiment dictionary
group_by(book, chapter) %>%   # Group the dataset by book and chapter
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>% # Create an index to split the chapters into 10 segments no matter how long the chapter it is
group_by(book, chapter, index) %>% # Regroup the dataset by book, chapter, and index
count(sentiment) %>%  # Count the occurrences of each sentiment within each segment
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% # Reshape the data from long to wide format
mutate(sentiment = positive - negative,index= as.factor(index))%>%  # Calculate sentiment score (positive - negative) for each segment
filter(!chapter=="0") # Filter out chapters with the value "0" (if any)
head(jane_austen_sentiment)
View(jane_austen_sentiment)
knitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE)
#install.packages("tidytext")
#install.packages("tidyverse")
#install.packages("janeaustenr")
#install.packages("magick")
library(tidytext) # to work with unstructured data
library(tidyverse) # to do data wrangling
get_sentiments("bing")
library(janeaustenr) # to fetch the dataset
library(magick) # to display images
# these are the libraries we need if you do not have them already and you get an error remove the # from the install.packages()lines
AustenTable <- austen_books() %>% #create a new file named AustenTable that will extract info from austen_books
group_by(book) %>% # group by every single book then
mutate( # manipulate the data to create
linenumber = row_number(), # a line number column that would count in which row the word was
chapter = cumsum(str_detect(text, # the chapter number. We can do so by using regex and find lines starting with chapter followed by a space and a letter
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>% #  This line removes the grouping, so subsequent operations will be applied to the entire dataset rather than grouped subsets.
unnest_tokens(word, text) # This tokenises the text column, splitting it into individual words and creating a new row for each word
head(AustenTable)
jane_austen_sentiment <- AustenTable %>% # Load Jane Austen's books dataset and start a chain of operations to create a Jane_austen_sentiment dataset
inner_join(get_sentiments("bing"), relationship = 'many-to-many') %>% # Join the dataset with the Bing lexicon sentiment dictionary
group_by(book, chapter) %>%   # Group the dataset by book and chapter
mutate(index = rep(1:10, each = ceiling(n() / 10), length.out = n())) %>% # Create an index to split the chapters into 10 segments no matter how long the chapter it is
group_by(book, chapter, index) %>% # Regroup the dataset by book, chapter, and index
count(sentiment) %>%  # Count the occurrences of each sentiment within each segment
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% # Reshape the data from long to wide format
mutate(sentiment = positive - negative,index= as.factor(index))%>%  # Calculate sentiment score (positive - negative) for each segment
filter(!chapter=="0") # Filter out chapters with the value "0" (if any)
head(jane_austen_sentiment)
dir_out <- file.path("outputs/Austen") # Define the directory path where the outputs will be saved
dir.create(dir_out, recursive = TRUE) # Create the directory if it doesn't already exist
books <- unique(jane_austen_sentiment$book)
books
most_chapter <- max(jane_austen_sentiment$chapter, na.rm = TRUE)# Find the maximum chapter number in the dataset 'jane_austen_sentiment'
most_chapter
for (y in books) {# Iterate over each book in the 'books' vector y is the name we are going to the iteration variable it can be anything as long as you are consistent
p <- # p is just a name we are giving to the plot again you can change it as long as you are consistent
jane_austen_sentiment %>%
filter(book == y) %>% # Filter the 'jane_austen_sentiment' dataset for the current book
ggplot(aes(chapter,index, fill= sentiment)) +  # Create a ggplot object with chapter, index, and sentiment as aesthetics
geom_tile() +# Add a tile layer to create a heatmap
scale_x_continuous(breaks=seq(1,most_chapter,1), expand = c(0,0))+  # Customise x-axis scale to show breaks from 1 to 'most_chapter'
scale_fill_gradient(low="blue", high="red", limits = c(-20, 40))+# Customise fill scale to use a gradient from blue to red
theme_bw()+ # Apply a black-and-white theme
guides(fill="none")+  # Remove the fill legend
ggtitle(y)+ # Add a title to the plot with the current book's name
coord_fixed(ratio = 1, ylim = c(10,1), xlim = c(0.5,most_chapter+0.5))+  # Fix the aspect ratio and set limits for y and x axes
theme(  # Customize theme to remove y-axis labels and ticks
axis.title.y = element_blank(),
axis.text.y= element_blank(),
axis.ticks.y = element_blank()
)
fp <- file.path(dir_out, paste0(y, ".png"))# Define the file path where the plot will be saved
ggsave(plot = p,  # Save the ggplot object as a PNG file
filename = fp,   # File path where the plot will be saved
device = "png", # Output device type (PNG format)
width=3500,# Width of the output in pixels
height = 1000, # Height of the output in pixels
units = "px") # Units of width and height (pixels)
}# Close the loop
Image <- image_read('outputs/Austen/Emma.png')
Image
imgs <- list.files(dir_out, full.names = TRUE) # List all file names in the directory 'dir_out' and store them in 'imgs'
img_list <- lapply(imgs, image_read)  # Read each image file from the list of file names using 'image_read' and store them in 'img_list'
img_joined <- image_join(img_list) # Join the list of images into a single animated image using 'image_join'
img_animated <- image_animate(img_joined, fps = 1) # Create an animated image from the joined image with a frame rate of 1 frame per second using 'image_animate'
image_write(image = img_animated,
path = "outputs/austen.gif")
img_animated
books <- unique(jane_austen_sentiment$book)
books
